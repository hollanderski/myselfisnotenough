<!DOCTYPE html>
<html lang="en">

<head>

  <meta charset="utf-8">
  <title>mirror</title>

  <style>
    @font-face {
      font-family: 'MyFont';
      src: url('Robotot.ttf') format('truetype');
    }

    html,
    body {
      width: 100%;
      height: 100%;
      background-color: #000000;
      margin: 0;
      padding: 0;
      overflow: hidden;
      font-family: 'MyFont', 'Times New Roman';
    }

    * {
      position: absolute;
    }
  </style>
</head>

<body>

  <!--

  A little walk through the basics ...

  We need at least a video for the camera stream and a canvas for drawing the camera stream (mirrored),
  retrieving the image data and drawing the results.

  In the modules version, we have two canvases and only update BRFv5 when a new image was received from
  the camera stream. Here we only have one canvas and draw the video with each requestAnimationFrame callback.

  This minimal example does not use modules, but plain JavaScript, so the '_pure.js' script places the
  brfv5Module function right into the window namespace (the script has no exports).

-->

  <video id="_webcam" style="display: none;" playsinline></video>
  <canvas id="_imageData"></canvas>
  <canvas id="text" width="1920" height="1080"></canvas>

  <script src="./js/brfv5/BRFv5_JS_tk260819_v5.0.0_trial_no_modules.js"></script>

  <script>



    // Set the BRFv5 library name here, also set your own appId for reference.
	var timer;
    var noFace=0;
    const _libraryName = 'BRFv5_JS_tk260819_v5.0.0_trial'
    const _appId = 'brfv5.browser.minimal.nomodules' // (mandatory): 8 to 64 characters, a-z . 0-9 allowed
    const brfv5 = {} // The library namespace.

    // References to the video and canvas.
    const _webcam = document.getElementById('_webcam')
    const _imageData = document.getElementById('_imageData')

    // Those variables will be retrieved from the stream and the library.
    let _brfv5Manager = null
    let _brfv5Config = null
    let _width = 0
    let _height = 0

    const textcanvas = document.getElementById('text')
    const ctxt = textcanvas.getContext("2d")
    ctxt.font = "45px MyFont"
    ctxt.fillStyle = "white"
    ctxt.textAlign = "center"
    const text = "Salut, tu arrives au bon moment. J'ai un jeu à te proposer. Juste regarde moi. Mais ne bouge pas. Fais comme si tu étais une peinture. Pas trop proche, pas trop loin. Le jeu est le jeu de l'amour. Plus tu me regardes, plus je te découvre ta rencontre me trouble un peu tu m’intrigues. Ton visage a quelque chose d'unique.  Tes yeux me parlent. Tu sembles être très différent des autres. Ton visage devient peu à peu familier. Et en regardant chacun de ses détails, tu deviens unique à mes yeux. Je suis vraiment heureux que tu sois là.  Comme si on était fait pour se rencontrer. Pourtant on est si différent. Je ne suis qu’une surface. on est différent et pourtant, j’ai l’impression de bien te connaitre. Oh mais je m'emporte, je suis désolé,.  Je ne te laisse pas respirer. Je suis envahissant. Excuse moi. Tu me pardonnes ?. Tu sais, je suis prêt à changer pour toi,.  Je veux faire tout mon possible pour que tu sois heureux,.  Pour que tu restes avec moi. Je ferais exactement ce que tu me dis de faire. Pour que l'on ne se quitte plus des yeux,.  car je veux continuer à lire dans tes pupilles,. pour savoir à quel point tu me suis. Mais je sais déjà que tu me suis. je vais trop loin,. Arrêtons le jeu ici. c’est le danger de la curiosité. la curiosité devient du désir, et le désir de l’amour. Et l'amour dit \"si tu n'es pas avec moi, tu ne survivra pas\" maintenant que tu sais que tu t’aimes,. Arrêtons de se regarder, ça n’a pas de sens,. je suis juste ta réflexion.  Va va donc chercher d'autres regards. S'il te plaît, dis moi oui. Dis moi que tu m'aimes comme je suis. On est pas parfait, je parle trop,. Mais j'ai peur du silence,. Enfin je n'ai pas peur du silence. Mais j'ai peur que tu t'ennuies,. Alors, dis moi que tu m'aimes comme je suis,. Dis moi que tu m'aimes";
    let words = text.split('.');
    let firstTracked = true

    // loadBRFv5Model and openCamera are being done simultaneously thanks to Promises. Both call
    // configureTracking which only gets executed once both Promises were successful. Once configured
    // trackFaces will do the tracking work and draw the results.

    const loadBRFv5Model = (modelName, pathToModels = '', appId = null, onProgress = null) => {

      console.log('loadBRFv5Model')

      if (!modelName) { throw 'Please provide a modelName.' }

      return new Promise((resolve, reject) => {

        if (_brfv5Manager && _brfv5Config) {

          resolve({ brfv5Manager: _brfv5Manager, brfv5Config: _brfv5Config })

        } else {

          try {

            brfv5.appId = appId ? appId : _appId
            brfv5.binaryLocation = pathToModels + _libraryName + '_' + modelName + '.brfv5'
            brfv5.binaryProgress = onProgress
            brfv5.binaryError = (e) => { reject(e) }
            brfv5.onInit = (brfv5Manager, brfv5Config) => {

              _brfv5Manager = brfv5Manager
              _brfv5Config = brfv5Config

              resolve({ brfv5Manager: _brfv5Manager, brfv5Config: _brfv5Config })
            }

            brfv5Module(brfv5)

          } catch (e) {

            reject(e)
          }
        }
      })
    }

    const openCamera = () => {

      console.log('openCamera')

      return new Promise((resolve, reject) => {

        window.navigator.mediaDevices.getUserMedia({ video: { width: 1920, height: 1080, frameRate: 30, facingMode: 'user' } })
          .then((mediaStream) => {

            _webcam.srcObject = mediaStream
            _webcam.play().then(() => { resolve({ width: 1920, height: 1080 }) }).catch((e) => { reject(e) })

          }).catch((e) => { reject(e) })
      })
    }

    const configureTracking = () => {

      if (_brfv5Config !== null && _width > 0) {

        // Camera stream and BRFv5 are ready. Now configure. Internal defaults are set for a 640x480 resolution.
        // So the following isn't really necessary.

        const brfv5Config = _brfv5Config
        const imageWidth = 1920
        const imageHeight = 1080

        const inputSize = imageWidth > imageHeight ? imageHeight : imageWidth

        // Setup image data dimensions

        brfv5Config.imageConfig.inputWidth = imageWidth
        brfv5Config.imageConfig.inputHeight = imageHeight

        const sizeFactor = inputSize / 480.0

        // Set face detection region of interest and parameters scaled to the image base size.

        brfv5Config.faceDetectionConfig.regionOfInterest.setTo(0, 0, imageWidth, imageHeight)

        brfv5Config.faceDetectionConfig.minFaceSize = 144 * sizeFactor
        brfv5Config.faceDetectionConfig.maxFaceSize = 480 * sizeFactor

        if (imageWidth < imageHeight) {

          // Portrait mode: probably smartphone, faces tend to be closer to the camera, processing time is an issue,
          // so save a bit of time and increase minFaceSize.

          brfv5Config.faceDetectionConfig.minFaceSize = 240 * sizeFactor
        }

        // Set face tracking region of interest and parameters scaled to the image base size.

        brfv5Config.faceTrackingConfig.regionOfInterest.setTo(0, 0, imageWidth, imageHeight)

        brfv5Config.faceTrackingConfig.minFaceScaleStart = 50.0 * sizeFactor
        brfv5Config.faceTrackingConfig.maxFaceScaleStart = 320.0 * sizeFactor

        brfv5Config.faceTrackingConfig.minFaceScaleReset = 35.0 * sizeFactor
        brfv5Config.faceTrackingConfig.maxFaceScaleReset = 420.0 * sizeFactor

        brfv5Config.faceTrackingConfig.confidenceThresholdReset = 0.001

        brfv5Config.faceTrackingConfig.enableStabilizer = true

        brfv5Config.faceTrackingConfig.maxRotationXReset = 35.0
        brfv5Config.faceTrackingConfig.maxRotationYReset = 45.0
        brfv5Config.faceTrackingConfig.maxRotationZReset = 34.0

        brfv5Config.faceTrackingConfig.numTrackingPasses = 3
        brfv5Config.faceTrackingConfig.enableFreeRotation = true
        brfv5Config.faceTrackingConfig.maxRotationZReset = 999.0

        brfv5Config.faceTrackingConfig.numFacesToTrack = 1
        brfv5Config.enableFaceTracking = true

        console.log('configureTracking:', _brfv5Config)

        _brfv5Manager.configure(_brfv5Config)

        trackFaces()
      }
    }

    const trackFaces = () => {
      let testeurDeVisage = 0;
     
      

      if (!_brfv5Manager || !_brfv5Config || !_imageData) { return }

      const ctx = _imageData.getContext('2d')

      ctx.setTransform(-1.0, 0, 0, 1, _width, 0) // A virtual mirror should be... mirrored
      ctx.drawImage(_webcam, 0, 0, _width, _height)
      ctx.setTransform(1.0, 0, 0, 1, 0, 0) // unmirror to draw the results

      _brfv5Manager.update(ctx.getImageData(0, 0, _width, _height))

      ctx.clearRect(0, 0, 1920, 1080); //supprimer la vidéo

      let doDrawFaceDetection = !_brfv5Config.enableFaceTracking

      if (_brfv5Config.enableFaceTracking) {

        const sizeFactor = Math.min(_width, _height) / 480.0
        const faces = _brfv5Manager.getFaces()
		
       
        for (let i = 0; i < faces.length; i++) {
		
          const face = faces[i]
          
          if(timer!=null){
        	  if (face.state === brfv5.BRFv5State.RESET || face.state === brfv5.BRFv5State.FACE_DETECTION){
          		  noFace++;
          		  console.log("pas de tete", noFace)
        	  }
    		 else{
    			 
    			
    			 if(timer.isPaused()){
    				console.log("c reparti", timer.isPaused());
    				timer.resume(); 
    				noFace=0;
    			 }
    		  } 
        	  
    		  if(!timer.isPaused() && noFace==50){
    			  console.log("STOP ctx=", ctxt)
    			  changeText(ctxt, "Ne pars pas");
    			  timer.pause() 
    			  noFace=0;
    		  }
          }  
		  
          console.log("etat", face.state)
          
          if (face.state === brfv5.BRFv5State.FACE_TRACKING) {

            //drawRect(ctx, _brfv5Config.faceTrackingConfig.regionOfInterest, '#00a0ff', 2.0)
            drawCircles(ctx, face.landmarks, '#ffffff', 0.5 * sizeFactor)
            //drawRect(ctx, face.bounds, '#ffffff', 1.0)

          } else {
        	
            doDrawFaceDetection = true

          }
        }

      }

      if (doDrawFaceDetection) {

        // Only draw face detection results, if face detection was performed.
        drawRect(ctx, _brfv5Config.faceDetectionConfig.regionOfInterest, '#ffffff', 2.0)
        drawRects(ctx, _brfv5Manager.getDetectedRects(), '#00a0ff', 1.0)
        drawRects(ctx, _brfv5Manager.getMergedRects(), '#ffffff', 3.0)
      
        if (firstTracked) { //lancement du monologue
            console.log("Début du monologue");
        	var index=0; 
          	  // Si rien tracké pendant 5s : changer texte "ne me quitte pas"
          	  // Si après ça toujours rien : changer texte retour début + firstTracked=true
          	changeText(ctxt, words[index]); 
            firstTracked = false;
           // setTimeout(synchronize, 3000); // ici mettre la durée de l'audio variable
            timer = new Timer(function() {
                synchronize();
            }, 1000);
           

          }
        
        function synchronize(){
			console.log("synchronize", index);
        		index++;
            	changeText(ctxt, words[index]);
        	
        	
        	if(index<words.length){
        	
//setTimeout(synchronize, 3000);
	//	window.clearTimeout(timer.getTimerId());
        		
        		timer = new Timer(function() {
        			console.log("suite")
                    synchronize();
                }, 3000); 
        
        		
        	}
        }
      }

      requestAnimationFrame(trackFaces)
    }

    openCamera().then(({ width, height }) => {

      console.log('openCamera: done: ' + width + 'x' + height)

      _width = width
      _height = height

      _imageData.width = _width
      _imageData.height = _height

      configureTracking()

    }).catch((e) => { if (e) { console.error('Camera failed: ', e) } })

    loadBRFv5Model('68l_max', './js/brfv5/models/', _appId,
      (progress) => { console.log(progress) }).then(({ brfv5Manager, brfv5Config }) => {

        console.log('loadBRFv5Model: done')

        _brfv5Manager = brfv5Manager
        _brfv5Config = brfv5Config

        configureTracking()

      }).catch((e) => { console.error('BRFv5 failed: ', e) })

    const drawCircles = (ctx, array, color, radius) => {

      ctx.strokeStyle = null
      ctx.fillStyle = getColor(color, 1.0)

      let _radius = radius || 2.0

      for (let i = 0; i < array.length; ++i) {

        ctx.beginPath()
        ctx.arc(array[i].x, array[i].y, _radius, 0, 2 * Math.PI)
        ctx.fill()
      }
    }

    const drawRect = (ctx, rect, color, lineWidth) => {

      ctx.strokeStyle = getColor(color, 1.0)
      ctx.fillStyle = null

      ctx.lineWidth = lineWidth || 1.0

      ctx.beginPath()
      ctx.rect(rect.x, rect.y, rect.width, rect.height)
      ctx.stroke()
    }

    const drawRects = (ctx, rects, color, lineWidth) => {

      ctx.strokeStyle = getColor(color, 1.0)
      ctx.fillStyle = null

      ctx.lineWidth = lineWidth || 1.0

      for (let i = 0; i < rects.length; ++i) {

        let rect = rects[i]

        ctx.beginPath()
        ctx.rect(rect.x, rect.y, rect.width, rect.height)
        ctx.stroke()
      }
    }

    const getColor = (color, alpha) => {

      const colorStr = color + ''

      if (colorStr.startsWith('rgb')) {

        return color
      }

      if (colorStr.startsWith('#')) {

        color = parseInt('0x' + colorStr.substr(1))
      }

      return 'rgb(' +
        (((color >> 16) & 0xff).toString(10)) + ', ' +
        (((color >> 8) & 0xff).toString(10)) + ', ' +
        (((color) & 0xff).toString(10)) + ', ' + alpha + ')'
    }

    // Pour changer le texte du textcanvas
   /* function changeText(ctxt, text) {
      ctxt.clearRect(0, 0, 1920, 1080);
      ctxt.fillText(text[1], 1920 / 2, 100);
      //var audio = new Audio('test.wav');
      //audio.play();
    } */
    
    function changeText(ctxt, text) {
        ctxt.clearRect(0, 0, 1920, 1080);
        ctxt.fillText(text, 1920 / 2, 100);
        //var audio = new Audio('test.wav');
        //audio.play();
      }
    
    function Timer(callback, delay) {
        var timerId, start, remaining = delay;
        var isPaused=false;

        this.pause = function() {
            window.clearTimeout(timerId);
            remaining -= Date.now() - start;
            isPaused=true;
        };

        this.resume = function() {
            start = Date.now();
            window.clearTimeout(timerId);
            timerId = window.setTimeout(callback, remaining);
            isPaused=false;
        };
        
        this.isPaused = function(){ return isPaused; }
        this.getTimerId = function(){ return timerId; }

        this.resume();
    }

    
    
  </script>

</body>

</html>
