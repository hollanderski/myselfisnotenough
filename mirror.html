<!DOCTYPE html>
<html lang="en">

<head>

  <meta charset="utf-8">
  <title>mirror</title>

  <style>
    @font-face {
      font-family: 'MyFont';
      src: url('Robotot.ttf') format('truetype');
    }

    html,
    body {
      width: 100%;
      height: 100%;
      background-color: #000000;
      margin: 0;
      padding: 0;
      overflow: hidden;
      font-family: 'MyFont', 'Times New Roman';
    }

    * {
      position: absolute;
    }
  </style>
</head>

<body>

  <!--

  A little walk through the basics ...

  We need at least a video for the camera stream and a canvas for drawing the camera stream (mirrored),
  retrieving the image data and drawing the results.

  In the modules version, we have two canvases and only update BRFv5 when a new image was received from
  the camera stream. Here we only have one canvas and draw the video with each requestAnimationFrame callback.

  This minimal example does not use modules, but plain JavaScript, so the '_pure.js' script places the
  brfv5Module function right into the window namespace (the script has no exports).

-->

  <video id="_webcam" style="display: none;" playsinline></video>
  <canvas id="_imageData"></canvas>
  <canvas id="text" width="1920" height="1080"></canvas>

  <script src="./js/brfv5/BRFv5_JS_tk260819_v5.0.0_trial_no_modules.js"></script>

  <script type="module">

	// Important pour dessiner les traits et isoler bouche, yeux, etc.
	import { faceTrianglesWithMouthWhole68l } from './js/utils/utils__face_triangles.js'

    // Set the BRFv5 library name here, also set your own appId for reference.
	var timer;
	var index;
    var audio;
    var noFace=0;
    var duration=3;
    const _libraryName = 'BRFv5_JS_tk260819_v5.0.0_trial'
    const _appId = 'brfv5.browser.minimal.nomodules' // (mandatory): 8 to 64 characters, a-z . 0-9 allowed
    const brfv5 = {} // The library namespace.

    // References to the video and canvas.
    const _webcam = document.getElementById('_webcam')
    const _imageData = document.getElementById('_imageData')

    // Those variables will be retrieved from the stream and the library.
    let _brfv5Manager = null
    let _brfv5Config = null
    let _width = 0
    let _height = 0

    const iWidth = 1920
    const iHeight = 1080

    const textcanvas = document.getElementById('text')
    const ctxt = textcanvas.getContext("2d")
    ctxt.font = "60px MyFont"
    ctxt.fillStyle = "white"
    ctxt.textAlign = "center"
    const text = "Salut, tu arrives au bon moment. J'ai un jeu à te proposer. Juste regarde moi. Mais ne bouge pas. Fais comme si tu étais une peinture. Pas trop proche, pas trop loin. Le jeu est le jeu de l'amour. Plus tu me regardes, plus je te découvre. Mais ta rencontre me trouble un peu. tu m’intrigues. Ton visage a quelque chose d'unique.  Tes yeux me parlent. Tu sembles être très différent des autres. Ton visage devient peu à peu familier. Et en regardant chacun de ses détails, tu deviens unique à mes yeux. Je suis vraiment heureux que tu sois là.  Comme si on était fait pour se rencontrer. Pourtant on est si différent. Je ne suis qu’une surface. on est différent et pourtant, j’ai l’impression de bien te connaitre. Oh mais je m'emporte, je suis désolé,.  Je ne te laisse pas respirer, je suis envahissant. Excuse moi. Tu me pardonnes ?. S'il te plaît, dis moi oui. Dis moi que tu m'aimes comme je suis. On est pas parfait, je parle trop. Mais j'ai peur du silence. Enfin je n'ai pas peur du silence. Mais j'ai peur que tu t'ennuies. Alors, dis moi que tu m'aimes comme je suis. Dis moi que tu m'aimes. Tu sais, je suis prêt à changer pour toi.  Je veux faire tout mon possible pour que tu sois heureux.  Pour que tu restes avec moi. Je ferai exactement ce que tu me dis de faire. Pour que l'on ne se quitte plus des yeux.  car je veux continuer à lire dans tes pupilles. pour savoir à quel point tu me follow. Mais je sais déjà que tu me follow. Ok, nous allons trop loin. Arrêtons de se regarder. Ça n’a pas de sens. Je suis juste ta réflexion. Arrêtons le jeu ici. c’est le danger de la curiosité. la curiosité devient du désir, et le désir de l’amour. Et l'amour dit si tu n'es pas avec moi, tu ne survivra pas. Maintenant que tu sais que tu t’aimes. Va, va donc chercher d'autres regards. .";
    let words = text.split('.');
    let firstTracked = true

    // loadBRFv5Model and openCamera are being done simultaneously thanks to Promises. Both call
    // configureTracking which only gets executed once both Promises were successful. Once configured
    // trackFaces will do the tracking work and draw the results.

    const loadBRFv5Model = (modelName, pathToModels = '', appId = null, onProgress = null) => {

      console.log('loadBRFv5Model')

      if (!modelName) { throw 'Please provide a modelName.' }

      return new Promise((resolve, reject) => {

        if (_brfv5Manager && _brfv5Config) {

          resolve({ brfv5Manager: _brfv5Manager, brfv5Config: _brfv5Config })

        } else {

          try {

            brfv5.appId = appId ? appId : _appId
            brfv5.binaryLocation = pathToModels + _libraryName + '_' + modelName + '.brfv5'
            brfv5.binaryProgress = onProgress
            brfv5.binaryError = (e) => { reject(e) }
            brfv5.onInit = (brfv5Manager, brfv5Config) => {

              _brfv5Manager = brfv5Manager
              _brfv5Config = brfv5Config

              resolve({ brfv5Manager: _brfv5Manager, brfv5Config: _brfv5Config })
            }

            brfv5Module(brfv5)

          } catch (e) {

            reject(e)
          }
        }
      })
    }

    const openCamera = () => {

      console.log('openCamera')

      return new Promise((resolve, reject) => {

        window.navigator.mediaDevices.getUserMedia({ video: { width: iWidth, height: iHeight, frameRate: 30, facingMode: 'user' } })
          .then((mediaStream) => {

            _webcam.srcObject = mediaStream
            _webcam.play().then(() => { resolve({ width: iWidth, height: iHeight }) }).catch((e) => { reject(e) })

          }).catch((e) => { reject(e) })
      })
    }

    const configureTracking = () => {

      if (_brfv5Config !== null && _width > 0) {

        // Camera stream and BRFv5 are ready. Now configure. Internal defaults are set for a 640x480 resolution.
        // So the following isn't really necessary.

        const brfv5Config = _brfv5Config
        const imageWidth = iWidth
        const imageHeight = iHeight

        const inputSize = imageWidth > imageHeight ? imageHeight : imageWidth

        // Setup image data dimensions

        brfv5Config.imageConfig.inputWidth = imageWidth
        brfv5Config.imageConfig.inputHeight = imageHeight

        const sizeFactor = inputSize / 480.0

        // Set face detection region of interest and parameters scaled to the image base size.

        brfv5Config.faceDetectionConfig.regionOfInterest.setTo(0, 0, imageWidth, imageHeight)

        brfv5Config.faceDetectionConfig.minFaceSize = 144 * sizeFactor
        brfv5Config.faceDetectionConfig.maxFaceSize = 480 * sizeFactor

        if (imageWidth < imageHeight) {

          // Portrait mode: probably smartphone, faces tend to be closer to the camera, processing time is an issue,
          // so save a bit of time and increase minFaceSize.

          brfv5Config.faceDetectionConfig.minFaceSize = 240 * sizeFactor
        }

        // Set face tracking region of interest and parameters scaled to the image base size.

        brfv5Config.faceTrackingConfig.regionOfInterest.setTo(0, 0, imageWidth, imageHeight)

        brfv5Config.faceTrackingConfig.minFaceScaleStart = 50.0 * sizeFactor
        brfv5Config.faceTrackingConfig.maxFaceScaleStart = 320.0 * sizeFactor

        brfv5Config.faceTrackingConfig.minFaceScaleReset = 35.0 * sizeFactor
        brfv5Config.faceTrackingConfig.maxFaceScaleReset = 420.0 * sizeFactor

        brfv5Config.faceTrackingConfig.confidenceThresholdReset = 0.001

        brfv5Config.faceTrackingConfig.enableStabilizer = true

        brfv5Config.faceTrackingConfig.maxRotationXReset = 35.0
        brfv5Config.faceTrackingConfig.maxRotationYReset = 45.0
        brfv5Config.faceTrackingConfig.maxRotationZReset = 34.0

        brfv5Config.faceTrackingConfig.numTrackingPasses = 3
        brfv5Config.faceTrackingConfig.enableFreeRotation = true
        brfv5Config.faceTrackingConfig.maxRotationZReset = 999.0

        brfv5Config.faceTrackingConfig.numFacesToTrack = 1
        brfv5Config.enableFaceTracking = true

        console.log('configureTracking:', _brfv5Config)

        _brfv5Manager.configure(_brfv5Config)

        trackFaces()
      }
    }

    const trackFaces = () => {
      let testeurDeVisage = 0;
     
      

      if (!_brfv5Manager || !_brfv5Config || !_imageData) { return }

      const ctx = _imageData.getContext('2d')

      ctx.setTransform(-1.0, 0, 0, 1, _width, 0) // A virtual mirror should be... mirrored
      ctx.drawImage(_webcam, 0, 0, _width, _height)
      ctx.setTransform(1.0, 0, 0, 1, 0, 0) // unmirror to draw the results

      _brfv5Manager.update(ctx.getImageData(0, 0, _width, _height))

      ctx.clearRect(0, 0, iWidth, iHeight); //supprimer la vidéo

      let doDrawFaceDetection = true; //!_brfv5Config.enableFaceTracking

      if (_brfv5Config.enableFaceTracking) {

        const sizeFactor = Math.min(_width, _height) / 480.0
        const faces = _brfv5Manager.getFaces()
		
       
        for (let i = 0; i < faces.length; i++) {
		
          const face = faces[i]
          
          if(timer!=null){
        	  if (face.state === brfv5.BRFv5State.RESET || face.state === brfv5.BRFv5State.FACE_DETECTION){
          		  noFace++;
          		  console.log("pas de tete", noFace)
        	  }
    		 else{
    			 
    			
    			 if(timer.isPaused()){
    				 
    				if(noFace<80)
    				{
						audio.pause();
        				timer.resume(); 
        				noFace=0;
    				}
    				else{ // Retour au début après 150 reset
						
    					window.clearTimeout(timer.getTimerId());
						window.clearTimeout(timer);
						timer=null;
    					firstTracked=true;
    					index=0;
    	    			noFace=0;
    				}
    			 }
    		  } 
        	  
    		  if(timer!=null && !timer.isPaused() && noFace==20){
    			 
				  audio.pause();
    			  changeText(ctxt, "S'il te plait, ne m'abandonne pas", "e"+(getRandomInt(2)+1));
    			  timer.pause() 
				 
    		  }
    		  if(timer!=null && timer.isPaused() && noFace>80){ // on rend vide le canvad (facultatif)
    			ctxt.clearRect(0, 0, 1920, 1080);
    		  }
    		  
          }  
		  
          console.log("etat", face.state)
          
          if (face.state === brfv5.BRFv5State.FACE_TRACKING) {

            //drawRect(ctx, _brfv5Config.faceTrackingConfig.regionOfInterest, '#00a0ff', 2.0)
            
			// Points :
			
			if(index>=8 && index<14){
				drawCircles(ctx, face.landmarks.slice(36,47), '#ffffff', 0.5 * sizeFactor);
			}	
			else if(index>8) drawCircles(ctx, face.landmarks, '#ffffff', 0.5 * sizeFactor)
			// à partir de 14 tout le visage, sinon juste yeux i.e 36-47 
			
			// Traits : 
            //drawTriangles(ctx, face.vertices, faceTrianglesWithMouthWhole68l, false, 1.0, 0x00a0ff, 0.4);
            
            //drawRect(ctx, face.bounds, '#ffffff', 1.0)

          } else {
        	
            doDrawFaceDetection = true

          }
        }

      }

      if (doDrawFaceDetection) {

        // Only draw face detection results, if face detection was performed.
        //drawRect(ctx, _brfv5Config.faceDetectionConfig.regionOfInterest, '#ffffff', 2.0)
        //drawRects(ctx, _brfv5Manager.getDetectedRects(), '#00a0ff', 1.0)
        //drawRects(ctx, _brfv5Manager.getMergedRects(), '#ffffff', 3.0)
      
	
        if (firstTracked) { //lancement du monologue
            console.log("Début du monologue");
        	 index=0; 
          	  // Si rien tracké pendant 5s : changer texte "ne me quitte pas"
          	  // Si après ça toujours rien : changer texte retour début + firstTracked=true
          	//changeText(ctxt, words[index], (index+1).toString()); 
            
           // setTimeout(synchronize, 3000); // ici mettre la durée de l'audio variable
          /*  timer = new Timer(function() {
                synchronize();
            }, 1000); */

		synchronize();

		firstTracked = false;
           

          }
        
        function synchronize(){
			console.log("synchronize", index);
        		
            	changeText(ctxt, words[index], (index+1).toString());
        		index++;
        	
        	if(index<words.length-1){
        	
//setTimeout(synchronize, 3000);
	//	window.clearTimeout(timer.getTimerId());
        		
        		timer = new Timer(function() {
        			console.log("suite")
                    synchronize();
        			console.log("duration=", duration);
                }, duration*1000+400);  //
        
        		
        	}
        	else{ // Recommence depuis le début du texte
        		window.clearTimeout(timer.getTimerId());
				window.clearTimeout(timer);
				timer=null;
				firstTracked=true;
				index=0;
    			noFace=0;
        	}
        }
      }

      requestAnimationFrame(trackFaces)
    }

    openCamera().then(({ width, height }) => {

      console.log('openCamera: done: ' + width + 'x' + height)

      _width = width
      _height = height

      _imageData.width = _width
      _imageData.height = _height

      configureTracking()

    }).catch((e) => { if (e) { console.error('Camera failed: ', e) } })

    loadBRFv5Model('68l_max', './js/brfv5/models/', _appId,
      (progress) => { console.log(progress) }).then(({ brfv5Manager, brfv5Config }) => {

        console.log('loadBRFv5Model: done')

        _brfv5Manager = brfv5Manager
        _brfv5Config = brfv5Config

        configureTracking()

      }).catch((e) => { console.error('BRFv5 failed: ', e) })

    const drawCircles = (ctx, array, color, radius) => {

      ctx.strokeStyle = null
      ctx.fillStyle = getColor(color, 1.0)

      let _radius = radius || 2.0

      for (let i = 0; i < array.length; ++i) {

        ctx.beginPath()
        ctx.arc(array[i].x, array[i].y, _radius, 0, 2 * Math.PI)
        ctx.fill()
      }
    }

    const drawRect = (ctx, rect, color, lineWidth) => {

      ctx.strokeStyle = getColor(color, 1.0)
      ctx.fillStyle = null

      ctx.lineWidth = lineWidth || 1.0

      ctx.beginPath()
      ctx.rect(rect.x, rect.y, rect.width, rect.height)
      ctx.stroke()
    }

    const drawRects = (ctx, rects, color, lineWidth) => {

      ctx.strokeStyle = getColor(color, 1.0)
      ctx.fillStyle = null

      ctx.lineWidth = lineWidth || 1.0

      for (let i = 0; i < rects.length; ++i) {

        let rect = rects[i]

        ctx.beginPath()
        ctx.rect(rect.x, rect.y, rect.width, rect.height)
        ctx.stroke()
      }
    }
    
    var defaultValue  = function(arg, val) {
        return typeof arg !== 'undefined' ? arg : val;
      };

    const drawTriangles = (g, vertices, triangles, clear, lineThickness, lineColor, lineAlpha) => {
        clear     = defaultValue(clear, false);
        lineThickness = defaultValue(lineThickness, 0.5);
        lineColor   = defaultValue(lineColor, 0x00a0ff);
        lineAlpha   = defaultValue(lineAlpha, 0.85);

        lineColor = getColor(lineColor, lineAlpha);


        clear && g.clear();

        var i = 0;
        var l = triangles.length;

        while(i < l) {
          var ti0 = triangles[i];
          var ti1 = triangles[i + 1];
          var ti2 = triangles[i + 2];

          var x0 = vertices[ti0 * 2];
          var y0 = vertices[ti0 * 2 + 1];
          var x1 = vertices[ti1 * 2];
          var y1 = vertices[ti1 * 2 + 1];
          var x2 = vertices[ti2 * 2];
          var y2 = vertices[ti2 * 2 + 1];


          g.strokeStyle="white";
          g.beginPath();

          g.moveTo(x0, y0);
          g.lineTo(x1, y1);
          g.lineTo(x2, y2);
          g.lineTo(x0, y0);

         g.stroke();


          i+=3;
        }
      };

    const getColor = (color, alpha) => {

      const colorStr = color + ''

      if (colorStr.startsWith('rgb')) {

        return color
      }

      if (colorStr.startsWith('#')) {

        color = parseInt('0x' + colorStr.substr(1))
      }

      return 'rgb(' +
        (((color >> 16) & 0xff).toString(10)) + ', ' +
        (((color >> 8) & 0xff).toString(10)) + ', ' +
        (((color) & 0xff).toString(10)) + ', ' + alpha + ')'
    }

  
	function getRandomInt(max) {
  		return Math.floor(Math.random() * Math.floor(max));
	}
    
    function changeText(ctxt, text, mp3) {
        
        audio = new Audio('voice/'+mp3+'.wav');
        audio.addEventListener('loadeddata', () => {
        	  duration = audio.duration;
        })
        audio.play();
		
		ctxt.clearRect(0, 0, iWidth, iHeight);
        ctxt.fillText(text, iWidth / 2, 100);
      }
    
    function Timer(callback, delay) {
        var timerId, start, remaining = delay;
        var isPaused=false;

        this.pause = function() {
            window.clearTimeout(timerId);
            remaining -= Date.now() - start;
            isPaused=true;
        };

        this.resume = function() {
            start = Date.now();
            window.clearTimeout(timerId);
            timerId = window.setTimeout(callback, remaining);
            isPaused=false;
        };
        
        this.isPaused = function(){ return isPaused; }
        this.getTimerId = function(){ return timerId; }

        this.resume();
    }

    
    
  </script>

</body>

</html>
